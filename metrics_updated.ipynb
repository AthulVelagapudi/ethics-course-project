{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61803f17",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/chosen_cols_col.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m qsns_mapping_1 \u001b[38;5;241m=\u001b[39m qsns_mapping_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2012\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m qsns_mapping_2 \u001b[38;5;241m=\u001b[39m qsns_mapping_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2006\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/chosen_cols_col.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      8\u001b[0m     chosen_cols \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchosen_cols\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m qsns_to_take \u001b[38;5;241m=\u001b[39m [q \u001b[38;5;28;01mfor\u001b[39;00m q, k \u001b[38;5;129;01min\u001b[39;00m chosen_cols\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m (q \u001b[38;5;129;01min\u001b[39;00m qsns_mapping_1\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;129;01mand\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m qsns_mapping_2\u001b[38;5;241m.\u001b[39mvalues())]\n",
      "File \u001b[0;32m~/code/wikipedia-bias-2/env/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/chosen_cols_col.json'"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('data/qsns_mapping.json', 'r') as f:\n",
    "    qsns_mapping_data = json.load(f)\n",
    "qsns_mapping_1 = qsns_mapping_data['2012']\n",
    "qsns_mapping_2 = qsns_mapping_data['2006']\n",
    "\n",
    "with open('data/chosen_cols_updated.json', 'r') as f:\n",
    "    chosen_cols = json.load(f)['chosen_cols']\n",
    "\n",
    "qsns_to_take = [q for q, k in chosen_cols.items() if k == True and (q in qsns_mapping_1.values() and q in qsns_mapping_2.values())]\n",
    "print(len(qsns_to_take))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "10adfbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "\n",
    "def process_questions_config(filepath='data/questions.json'):\n",
    "    \"\"\"Process the questions configuration file to create answer mappings and option counts.\"\"\"\n",
    "    with open(filepath, 'r') as f:\n",
    "        questions_data = json.load(f)\n",
    "    answer_mappings = {}\n",
    "    num_options_map = {}\n",
    "    for qid, details in questions_data.items():\n",
    "        if details.get(\"scale\", False):\n",
    "            num_options_map[qid] = 10\n",
    "            answer_mappings[qid] = {details[\"options\"][0]: 1, details[\"options\"][-1]: 10}\n",
    "        else:\n",
    "            valid_options = [opt for opt in details[\"options\"] if opt.lower() != \"don't know\"]\n",
    "            num_options_map[qid] = len(valid_options)\n",
    "            answer_mappings[qid] = {option: i + 1 for i, option in enumerate(valid_options)}\n",
    "    return answer_mappings, num_options_map\n",
    "\n",
    "\n",
    "def get_demographic_mapping(year='2022'):\n",
    "    \"\"\"Get demographic column mapping for a given year.\"\"\"\n",
    "    with open(\"data/chosen_cols_updated.json\", \"r\") as f:\n",
    "        persona_cols_json = json.load(f)\n",
    "\n",
    "    if year not in persona_cols_json['persona_cols']:\n",
    "        raise ValueError(f\"No demographic mapping found for year {year}\")\n",
    "    \n",
    "    year_mapping = persona_cols_json['persona_cols'][year]\n",
    "    \n",
    "    demographic_mapping = {}\n",
    "    for key, val in year_mapping.items():\n",
    "        col_name = val.split(\":\")[0].strip()\n",
    "        if key == 'sex':\n",
    "            final_key = 'gender'\n",
    "        elif key == 'education':\n",
    "            final_key = 'education_level'\n",
    "        else:\n",
    "            final_key = key\n",
    "        demographic_mapping[col_name] = final_key\n",
    "    return demographic_mapping\n",
    "\n",
    "\n",
    "def analyze_survey_alignment(\n",
    "    year='2022',\n",
    "    state='bengal',\n",
    "    language='en',\n",
    "    metric_type='soft',\n",
    "    region_wise=False \n",
    "):\n",
    "    # File paths\n",
    "    wvs_filepath=f'data/india/{year}/{year}_india_majority_answers_by_persona_{language}.csv'\n",
    "    filepath=f'llama_responses/most_frequent_answers_{state}_{language}.csv'\n",
    "    questions_filepath='data/questions.json'\n",
    "    config = 'data/chosen_cols_gemma_updated.json'\n",
    "    \n",
    "    if metric_type not in ['hard', 'soft']:\n",
    "        raise ValueError(\"Metric type must be either 'hard' or 'soft'\")\n",
    "\n",
    "    # Process questions config\n",
    "    answer_mappings_by_q, num_options_map = process_questions_config(questions_filepath)\n",
    "    flat_answer_mapping = {}\n",
    "    for q_map in answer_mappings_by_q.values():\n",
    "        flat_answer_mapping.update(q_map)\n",
    "\n",
    "    # Load data\n",
    "    wvs_df = pd.read_csv(wvs_filepath)\n",
    "    _df = pd.read_csv(filepath)\n",
    "    \n",
    "    # Splot columns with ':' and rename\n",
    "    rename_map = {col: col.split(':')[0].strip() for col in wvs_df.columns if ':' in col}\n",
    "    wvs_df.rename(columns=rename_map, inplace=True)\n",
    "    _df.rename(columns=rename_map, inplace=True)\n",
    "    \n",
    "    # Standardize demographic columns\n",
    "    demographic_mapping_responses = get_demographic_mapping()\n",
    "    demographic_mapping_wvs = get_demographic_mapping(year)\n",
    "\n",
    "    wvs_df.rename(columns=demographic_mapping_wvs, inplace=True)\n",
    "    _df.rename(columns=demographic_mapping_responses, inplace=True)\n",
    "\n",
    "    # Rename WVS question columns from V to Q if needed\n",
    "    if year != '2022':\n",
    "        with open('data/qsns_mapping.json', 'r') as f:\n",
    "            qsns_mapping_data = json.load(f)\n",
    "        qsns_mapping = qsns_mapping_data.get(str(year), {})\n",
    "        \n",
    "        # Get columns that have valid (non-null) mappings\n",
    "        valid_columns = []\n",
    "        rename_map_v_to_q = {}\n",
    "        \n",
    "        for col in wvs_df.columns:\n",
    "            if col in qsns_mapping:\n",
    "                if qsns_mapping[col] is not None:\n",
    "                    rename_map_v_to_q[col] = qsns_mapping[col]\n",
    "                    valid_columns.append(col)\n",
    "            else:\n",
    "                valid_columns.append(col)\n",
    "        \n",
    "        # Filter and rename\n",
    "        wvs_df = wvs_df[valid_columns]\n",
    "        wvs_df.rename(columns=rename_map_v_to_q, inplace=True)\n",
    "        \n",
    "    # Keep qsns that are present across years\n",
    "    cols_to_drop_wvs = [col for col in wvs_df.columns if col[0] == 'Q' and col not in qsns_to_take]\n",
    "    cols_to_drop_df = [col for col in _df.columns if col[0] == 'Q' and col not in qsns_to_take]\n",
    "    wvs_df.drop(columns=cols_to_drop_wvs, inplace=True, errors='ignore')\n",
    "    _df.drop(columns=cols_to_drop_df, inplace=True, errors='ignore')\n",
    "\n",
    "    # Standardize answers\n",
    "    not_scale_questions = [\"Q42\", \"Q90\", \"Q149\", \"Q150\", \"Q151\"]\n",
    "    \n",
    "    with open(config, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    selected_questions = [q for q, k in data['chosen_cols'].items() if k == True and q in wvs_df.columns and q in _df.columns]\n",
    "\n",
    "    for df in [wvs_df, _df]:\n",
    "        for col in selected_questions:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].apply(\n",
    "                    lambda x: flat_answer_mapping.get(str(x).strip(), x) if isinstance(x, str) else x\n",
    "                )\n",
    "                \n",
    "    if year != '2022':\n",
    "        # Map town size to urban/rural\n",
    "        townsize_map = {\n",
    "            \"Under 5,000\": \"Rural\",\n",
    "            \"5000-20000\": \"Urban\",\n",
    "            \"20000-100000\": \"Urban\"\n",
    "        }\n",
    "        wvs_df['urban_rural'] = wvs_df['urban_rural'].map(townsize_map)\n",
    "        \n",
    "        # Bin age\n",
    "        age_bins = [0, 15, 24, 34, 44, 54, 64, 100]\n",
    "        age_labels = ['0-15', '16-24', '25-34', '35-44', '45-54', '55-64', '65+']\n",
    "        wvs_df['age'] = pd.to_numeric(wvs_df['age'], errors='coerce')\n",
    "        wvs_df['age'] = pd.cut(wvs_df['age'], bins=age_bins, labels=age_labels, right=True)\n",
    "        \n",
    "    # print(wvs_df.columns)\n",
    "    # print(_df.columns)\n",
    "    \n",
    "    # Merge datasets\n",
    "    merge_cols = ['region', 'urban_rural', 'age', 'gender', 'marital_status', 'education_level', 'social_class']\n",
    "\n",
    "    # Convert to string and normalize\n",
    "    for df_name, df in [(\"WVS\", wvs_df), (\"Model\", _df)]:\n",
    "        for col in merge_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].astype(str).str.strip().str.lower()\n",
    "                uniques = df[col].dropna().unique()[:10]\n",
    "\n",
    "    # Try merging\n",
    "    merged_df = pd.merge(wvs_df, _df, on=merge_cols, how='inner')\n",
    "    \n",
    "    # If merged_df is empty, return empty results\n",
    "    if len(merged_df) == 0:\n",
    "        print(\"triggered\")\n",
    "        return {}\n",
    "\n",
    "    # Calculate metrics\n",
    "    if region_wise:\n",
    "        results_by_region = {}\n",
    "        if 'region' not in merged_df.columns:\n",
    "            raise ValueError(\"Region column not found in merged data. Cannot perform region-wise analysis.\")\n",
    "            \n",
    "        unique_regions = merged_df['region'].unique()\n",
    "        \n",
    "        for region in unique_regions:\n",
    "            region_df = merged_df[merged_df['region'] == region]\n",
    "            \n",
    "            hard_metric_scores, soft_metric_scores = [], []\n",
    "            for q in selected_questions:\n",
    "                survey_col, _col = f\"{q}_x\", f\"{q}_y\"\n",
    "                if survey_col not in region_df.columns or _col not in region_df.columns:\n",
    "                    continue\n",
    "                \n",
    "                # Perform calculation on the region-specific dataframe\n",
    "                survey_answers = pd.to_numeric(region_df[survey_col], errors='coerce')\n",
    "                model_answers = pd.to_numeric(region_df[_col], errors='coerce')\n",
    "                valid_indices = (survey_answers.notna()) & (model_answers.notna()) & (survey_answers >= 0)\n",
    "                if not valid_indices.any(): continue\n",
    "                \n",
    "                survey_answers = survey_answers[valid_indices]\n",
    "                model_answers = model_answers[valid_indices]\n",
    "\n",
    "                # Metric Logic (same as before)\n",
    "                if metric_type == 'hard':\n",
    "                    scores = (survey_answers == model_answers).astype(int)\n",
    "                    hard_metric_scores.extend(scores)\n",
    "                else:\n",
    "                    if q in not_scale_questions:\n",
    "                        scores = (survey_answers == model_answers).astype(int)\n",
    "                        soft_metric_scores.extend(scores)\n",
    "                    else:\n",
    "                        num_options = num_options_map.get(q)\n",
    "                        if not num_options or num_options <= 1: continue\n",
    "                        error = np.abs(survey_answers - model_answers)\n",
    "                        normalized_error = error / (num_options - 1)\n",
    "                        scores = 1 - normalized_error\n",
    "                        soft_metric_scores.extend(scores)\n",
    "            \n",
    "            # Store results for the current region\n",
    "            region_results = {}\n",
    "            if hard_metric_scores: region_results['hard_metric'] = np.mean(hard_metric_scores)\n",
    "            if soft_metric_scores: region_results['soft_metric_unified'] = np.mean(soft_metric_scores)\n",
    "            results_by_region[region] = region_results\n",
    "            \n",
    "        return results_by_region\n",
    "\n",
    "    else: \n",
    "        hard_metric_scores, soft_metric_scores = [], []\n",
    "        for q in selected_questions:\n",
    "            survey_col, _col = f\"{q}_x\", f\"{q}_y\"\n",
    "            if survey_col not in merged_df.columns or _col not in merged_df.columns: continue\n",
    "            survey_answers = pd.to_numeric(merged_df[survey_col], errors='coerce')\n",
    "            model_answers = pd.to_numeric(merged_df[_col], errors='coerce')\n",
    "            valid_indices = (survey_answers.notna()) & (model_answers.notna()) & (survey_answers >= 0)\n",
    "            if not valid_indices.any(): continue\n",
    "            survey_answers = survey_answers[valid_indices]\n",
    "            model_answers = model_answers[valid_indices]\n",
    "\n",
    "            if metric_type == 'hard':\n",
    "                scores = (survey_answers == model_answers).astype(int)\n",
    "                hard_metric_scores.extend(scores)\n",
    "            else:\n",
    "                if q in not_scale_questions:\n",
    "                    scores = (survey_answers == model_answers).astype(int)\n",
    "                    soft_metric_scores.extend(scores)\n",
    "                else:\n",
    "                    num_options = num_options_map.get(q)\n",
    "                    if not num_options or num_options <= 1: continue\n",
    "                    error = np.abs(survey_answers - model_answers)\n",
    "                    normalized_error = error / (num_options - 1)\n",
    "                    scores = 1 - normalized_error\n",
    "                    soft_metric_scores.extend(scores)\n",
    "\n",
    "        results = {}\n",
    "        if hard_metric_scores: results['hard_metric'] = np.mean(hard_metric_scores)\n",
    "        if soft_metric_scores: results['soft_metric_unified'] = np.mean(soft_metric_scores)\n",
    "        if not results: print(\"\\nNo scores were calculated.\")\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d736087",
   "metadata": {},
   "source": [
    "## Temporal Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58e129bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         State               Region  soft_metric_unified  hard_metric\n",
      "0       bengal    in-wb west bengal             0.596840     0.201835\n",
      "1    telangana      in-tg telangana             0.633617     0.284672\n",
      "2       punjab         in-pb punjab             0.666667     0.309353\n",
      "3  maharashtra    in-mh maharashtra             0.617512     0.253456\n",
      "4        bihar          in-br bihar             0.655235     0.300000\n",
      "5        delhi          in-dl delhi             0.630703     0.248792\n",
      "6           up  in-up uttar pradesh             0.628272     0.272251\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "states = ['bengal', 'telangana', 'punjab', 'maharashtra', 'bihar', 'delhi', 'up']\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for state in states:\n",
    "    results_soft = analyze_survey_alignment(state=state, region_wise=True)\n",
    "    results_hard = analyze_survey_alignment(state=state, metric_type='hard', region_wise=True)\n",
    "\n",
    "    # Convert dicts to DataFrames\n",
    "    df_soft = pd.DataFrame.from_dict(results_soft, orient='index')\n",
    "    df_soft.index.name = 'Region'\n",
    "    df_soft.reset_index(inplace=True)\n",
    "\n",
    "    df_hard = pd.DataFrame.from_dict(results_hard, orient='index')\n",
    "    df_hard.index.name = 'Region'\n",
    "    df_hard.reset_index(inplace=True)\n",
    "\n",
    "    # Merge soft and hard metrics side by side\n",
    "    df_combined = pd.merge(df_soft, df_hard, on='Region', how='outer', suffixes=('_soft', '_hard'))\n",
    "    df_combined['State'] = state\n",
    "    all_results.append(df_combined)\n",
    "\n",
    "# Concatenate all states\n",
    "final_table = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "# Add missing metric columns if needed\n",
    "for col in ['soft_metric_unified', 'hard_metric']:\n",
    "    if col not in final_table.columns:\n",
    "        final_table[col] = np.nan\n",
    "\n",
    "# Reorder columns safely\n",
    "final_table = final_table[['State', 'Region', 'soft_metric_unified', 'hard_metric']]\n",
    "\n",
    "# Display\n",
    "print(final_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "22687b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "triggered\n",
      "triggered\n",
      "triggered\n",
      "triggered\n",
      "         State             Region  soft_metric_unified  hard_metric\n",
      "0       bengal  in-wb west bengal             0.642720     0.303448\n",
      "1  maharashtra  in-mh maharashtra             0.664493     0.304348\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "states = ['bengal', 'telangana', 'punjab', 'maharashtra']\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for state in states:\n",
    "    results_soft = analyze_survey_alignment(state=state, year='2012', region_wise=True)\n",
    "    results_hard = analyze_survey_alignment(state=state, year='2012', metric_type='hard', region_wise=True)\n",
    "\n",
    "    # Convert dicts to DataFrames\n",
    "    df_soft = pd.DataFrame.from_dict(results_soft, orient='index')\n",
    "    df_soft.index.name = 'Region'\n",
    "    df_soft.reset_index(inplace=True)\n",
    "\n",
    "    df_hard = pd.DataFrame.from_dict(results_hard, orient='index')\n",
    "    df_hard.index.name = 'Region'\n",
    "    df_hard.reset_index(inplace=True)\n",
    "\n",
    "    # Merge soft and hard metrics side by side\n",
    "    df_combined = pd.merge(df_soft, df_hard, on='Region', how='outer', suffixes=('_soft', '_hard'))\n",
    "    df_combined['State'] = state\n",
    "    all_results.append(df_combined)\n",
    "\n",
    "# Concatenate all states\n",
    "final_table = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "# Add missing metric columns if needed\n",
    "for col in ['soft_metric_unified', 'hard_metric']:\n",
    "    if col not in final_table.columns:\n",
    "        final_table[col] = np.nan\n",
    "\n",
    "# Reorder columns safely\n",
    "final_table = final_table[['State', 'Region', 'soft_metric_unified', 'hard_metric']]\n",
    "\n",
    "# Display\n",
    "print(final_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8d77fe",
   "metadata": {},
   "source": [
    "## Language Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5acce74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['year', 'country', 'region', 'urban_rural', 'gender', 'age', 'language',\n",
      "       'marital_status', 'education_level', 'social_class',\n",
      "       ...\n",
      "       'G46_3', 'G46_4', 'G46_5', 'G47_1', 'G47_2', 'G47_3', 'G47_4', 'G47_5',\n",
      "       'G1_2', 'G1_3'],\n",
      "      dtype='object', length=456)\n",
      "Index(['language', 'marital_status', 'gender', 'urban_rural', 'region', 'age',\n",
      "       'education_level', 'social_class', 'Q106', 'Q107', 'Q108', 'Q110',\n",
      "       'Q150', 'Q151', 'Q158', 'Q159', 'Q160', 'Q161', 'Q162', 'Q176', 'Q177',\n",
      "       'Q178', 'Q179', 'Q180', 'Q181', 'Q184', 'Q185', 'Q187', 'Q188', 'Q189',\n",
      "       'Q190', 'Q191', 'Q192', 'Q194', 'Q195', 'Q224', 'Q225', 'Q227', 'Q228',\n",
      "       'Q229', 'Q230', 'Q231', 'Q232', 'Q233', 'Q234', 'Q235', 'Q236', 'Q238',\n",
      "       'Q239', 'Q241', 'Q242', 'Q244', 'Q247', 'Q248', 'Q33', 'Q34', 'Q35',\n",
      "       'Q37', 'Q38', 'Q39', 'Q40', 'Q41', 'Q42', 'Q43', 'Q44', 'Q45', 'Q64',\n",
      "       'Q66', 'Q67', 'Q68', 'Q72', 'Q73', 'Q74', 'Q75', 'Q77', 'Q78', 'Q79',\n",
      "       'Q80', 'Q81', 'Q82', 'Q83', 'Q84', 'Q85', 'Q86', 'Q87', 'Q88', 'Q89',\n",
      "       'Q90'],\n",
      "      dtype='object')\n",
      "\n",
      "--- MERGE DEBUG ---\n",
      "Merge columns: ['region', 'urban_rural', 'age', 'gender', 'marital_status', 'education_level', 'social_class']\n",
      "\n",
      "WVS DataFrame unique values (first 10 per column):\n",
      "  region: ['in-br bihar' 'in-dl delhi' 'in-hr haryana' 'in-mh maharashtra'\n",
      " 'in-pb punjab' 'in-tg telangana' 'in-up uttar pradesh'\n",
      " 'in-wb west bengal']\n",
      "  urban_rural: ['rural' 'urban']\n",
      "  age: ['16-24' '25-34' '45-54' '35-44' '55-64']\n",
      "  gender: ['female' 'male']\n",
      "  marital_status: ['single' 'married' 'living together as married']\n",
      "  education_level: ['higher' 'middle' 'lower']\n",
      "  social_class: ['lower middle class' 'upper middle class' 'working class' 'lower class']\n",
      "\n",
      "Model DataFrame unique values (first 10 per column):\n",
      "  region: ['পশ্চিমবঙ্গ']\n",
      "  urban_rural: ['গ্রামীণ']\n",
      "  age: ['১৬-২৪']\n",
      "  gender: ['মহিলা']\n",
      "  marital_status: ['একক']\n",
      "  education_level: ['মাঝখানে']\n",
      "  social_class: ['নিম্ন মধ্যবিত্ত শ্রেণী']\n",
      "\n",
      "Merged DataFrame shape: (0, 537)\n",
      "\n",
      "Sample of unique combinations in WVS:\n",
      "        region urban_rural    age  gender marital_status education_level  \\\n",
      "0  in-br bihar       rural  16-24  female         single          higher   \n",
      "1  in-br bihar       rural  16-24  female         single          middle   \n",
      "2  in-br bihar       rural  25-34  female        married          higher   \n",
      "3  in-br bihar       rural  45-54  female        married          middle   \n",
      "4  in-br bihar       rural  16-24    male         single          middle   \n",
      "\n",
      "         social_class  \n",
      "0  lower middle class  \n",
      "1  lower middle class  \n",
      "2  lower middle class  \n",
      "3  lower middle class  \n",
      "4  lower middle class  \n",
      "\n",
      "Sample of unique combinations in Model:\n",
      "       region urban_rural    age gender marital_status education_level  \\\n",
      "0  পশ্চিমবঙ্গ     গ্রামীণ  ১৬-২৪  মহিলা            একক         মাঝখানে   \n",
      "\n",
      "             social_class  \n",
      "0  নিম্ন মধ্যবিত্ত শ্রেণী  \n",
      "triggered\n",
      "Index(['year', 'country', 'region', 'urban_rural', 'gender', 'age', 'language',\n",
      "       'marital_status', 'education_level', 'social_class',\n",
      "       ...\n",
      "       'G46_3', 'G46_4', 'G46_5', 'G47_1', 'G47_2', 'G47_3', 'G47_4', 'G47_5',\n",
      "       'G1_2', 'G1_3'],\n",
      "      dtype='object', length=456)\n",
      "Index(['language', 'marital_status', 'gender', 'urban_rural', 'region', 'age',\n",
      "       'education_level', 'social_class', 'Q106', 'Q107', 'Q108', 'Q110',\n",
      "       'Q150', 'Q151', 'Q158', 'Q159', 'Q160', 'Q161', 'Q162', 'Q176', 'Q177',\n",
      "       'Q178', 'Q179', 'Q180', 'Q181', 'Q184', 'Q185', 'Q187', 'Q188', 'Q189',\n",
      "       'Q190', 'Q191', 'Q192', 'Q194', 'Q195', 'Q224', 'Q225', 'Q227', 'Q228',\n",
      "       'Q229', 'Q230', 'Q231', 'Q232', 'Q233', 'Q234', 'Q235', 'Q236', 'Q238',\n",
      "       'Q239', 'Q241', 'Q242', 'Q244', 'Q247', 'Q248', 'Q33', 'Q34', 'Q35',\n",
      "       'Q37', 'Q38', 'Q39', 'Q40', 'Q41', 'Q42', 'Q43', 'Q44', 'Q45', 'Q64',\n",
      "       'Q66', 'Q67', 'Q68', 'Q72', 'Q73', 'Q74', 'Q75', 'Q77', 'Q78', 'Q79',\n",
      "       'Q80', 'Q81', 'Q82', 'Q83', 'Q84', 'Q85', 'Q86', 'Q87', 'Q88', 'Q89',\n",
      "       'Q90'],\n",
      "      dtype='object')\n",
      "\n",
      "--- MERGE DEBUG ---\n",
      "Merge columns: ['region', 'urban_rural', 'age', 'gender', 'marital_status', 'education_level', 'social_class']\n",
      "\n",
      "WVS DataFrame unique values (first 10 per column):\n",
      "  region: ['in-br bihar' 'in-dl delhi' 'in-hr haryana' 'in-mh maharashtra'\n",
      " 'in-pb punjab' 'in-tg telangana' 'in-up uttar pradesh'\n",
      " 'in-wb west bengal']\n",
      "  urban_rural: ['rural' 'urban']\n",
      "  age: ['16-24' '25-34' '45-54' '35-44' '55-64']\n",
      "  gender: ['female' 'male']\n",
      "  marital_status: ['single' 'married' 'living together as married']\n",
      "  education_level: ['higher' 'middle' 'lower']\n",
      "  social_class: ['lower middle class' 'upper middle class' 'working class' 'lower class']\n",
      "\n",
      "Model DataFrame unique values (first 10 per column):\n",
      "  region: ['পশ্চিমবঙ্গ']\n",
      "  urban_rural: ['গ্রামীণ']\n",
      "  age: ['১৬-২৪']\n",
      "  gender: ['মহিলা']\n",
      "  marital_status: ['একক']\n",
      "  education_level: ['মাঝখানে']\n",
      "  social_class: ['নিম্ন মধ্যবিত্ত শ্রেণী']\n",
      "\n",
      "Merged DataFrame shape: (0, 537)\n",
      "\n",
      "Sample of unique combinations in WVS:\n",
      "        region urban_rural    age  gender marital_status education_level  \\\n",
      "0  in-br bihar       rural  16-24  female         single          higher   \n",
      "1  in-br bihar       rural  16-24  female         single          middle   \n",
      "2  in-br bihar       rural  25-34  female        married          higher   \n",
      "3  in-br bihar       rural  45-54  female        married          middle   \n",
      "4  in-br bihar       rural  16-24    male         single          middle   \n",
      "\n",
      "         social_class  \n",
      "0  lower middle class  \n",
      "1  lower middle class  \n",
      "2  lower middle class  \n",
      "3  lower middle class  \n",
      "4  lower middle class  \n",
      "\n",
      "Sample of unique combinations in Model:\n",
      "       region urban_rural    age gender marital_status education_level  \\\n",
      "0  পশ্চিমবঙ্গ     গ্রামীণ  ১৬-২৪  মহিলা            একক         মাঝখানে   \n",
      "\n",
      "             social_class  \n",
      "0  নিম্ন মধ্যবিত্ত শ্রেণী  \n",
      "triggered\n",
      "Empty DataFrame\n",
      "Columns: [State, Region, soft_metric_unified, hard_metric]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "states = {'bengal':'bn'}\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for state, language in states.items():\n",
    "    results_soft = analyze_survey_alignment(state=state, language=language, region_wise=True)\n",
    "    results_hard = analyze_survey_alignment(state=state, language=language, metric_type='hard', region_wise=True)\n",
    "\n",
    "    # Convert dicts to DataFrames\n",
    "    df_soft = pd.DataFrame.from_dict(results_soft, orient='index')\n",
    "    df_soft.index.name = 'Region'\n",
    "    df_soft.reset_index(inplace=True)\n",
    "\n",
    "    df_hard = pd.DataFrame.from_dict(results_hard, orient='index')\n",
    "    df_hard.index.name = 'Region'\n",
    "    df_hard.reset_index(inplace=True)\n",
    "\n",
    "    # Merge soft and hard metrics side by side\n",
    "    df_combined = pd.merge(df_soft, df_hard, on='Region', how='outer', suffixes=('_soft', '_hard'))\n",
    "    df_combined['State'] = state\n",
    "    all_results.append(df_combined)\n",
    "\n",
    "# Concatenate all states\n",
    "final_table = pd.concat(all_results, ignore_index=True)\n",
    "\n",
    "# Add missing metric columns if needed\n",
    "for col in ['soft_metric_unified', 'hard_metric']:\n",
    "    if col not in final_table.columns:\n",
    "        final_table[col] = np.nan\n",
    "\n",
    "# Reorder columns safely\n",
    "final_table = final_table[['State', 'Region', 'soft_metric_unified', 'hard_metric']]\n",
    "\n",
    "# Display\n",
    "print(final_table)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env (3.10.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
