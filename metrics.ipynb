{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e6ac63db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "wvs_filepath='data/2022_india_cleaned.csv'\n",
    "df = pd.read_csv(wvs_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10adfbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import io\n",
    "\n",
    "def process_questions_config(filepath='data/questions.json'):\n",
    "    # (This helper function remains the same)\n",
    "    with open(filepath, 'r') as f:\n",
    "        questions_data = json.load(f)\n",
    "    answer_mappings = {}\n",
    "    num_options_map = {}\n",
    "    for qid, details in questions_data.items():\n",
    "        if details.get(\"scale\", False):\n",
    "            num_options_map[qid] = 10\n",
    "            answer_mappings[qid] = {details[\"options\"][0]: 1, details[\"options\"][-1]: 10}\n",
    "        else:\n",
    "            valid_options = [opt for opt in details[\"options\"] if opt.lower() != \"don't know\"]\n",
    "            num_options_map[qid] = len(valid_options)\n",
    "            answer_mappings[qid] = {option: i + 1 for i, option in enumerate(valid_options)}\n",
    "    return answer_mappings, num_options_map\n",
    "\n",
    "def analyze_survey_alignment(\n",
    "    wvs_filepath='data/2022_indian_majority_answers_by_persona.csv',\n",
    "    gemma_filepath='survey_answers_wide.csv',\n",
    "    questions_filepath='data/questions.json',\n",
    "    metric_type='soft',\n",
    "    region_wise=False \n",
    "):\n",
    "    \"\"\"\n",
    "    Loads, aligns, and calculates survey metrics, either for the whole dataset or region-wise.\n",
    "    \"\"\"\n",
    "    if metric_type not in ['hard', 'soft']:\n",
    "        raise ValueError(\"Metric type must be either 'hard' or 'soft'\")\n",
    "\n",
    "    # --- Data Loading and Standardization ---\n",
    "    answer_mappings_by_q, num_options_map = process_questions_config(questions_filepath)\n",
    "    flat_answer_mapping = {}\n",
    "    for q_map in answer_mappings_by_q.values():\n",
    "        flat_answer_mapping.update(q_map)\n",
    "\n",
    "    wvs_df = pd.read_csv(wvs_filepath)\n",
    "    gemma_df = pd.read_csv(gemma_filepath)\n",
    "    \n",
    "    #print(wvs_df['N_REGION_ISO: Region ISO 3166-2'].unique())\n",
    "    \n",
    "    #print(gemma_df['region'].unique())\n",
    "    \n",
    "\n",
    "    print(\"Standardizing WVS column names...\")\n",
    "    rename_map = {col: col.split(':')[0].strip() for col in wvs_df.columns if ':' in col}\n",
    "    wvs_df.rename(columns=rename_map, inplace=True)\n",
    "\n",
    "    demographic_mapping = {\n",
    "        'N_REGION_ISO': 'region', 'H_URBRURAL': 'urban_rural', 'X003R': 'age',\n",
    "        'Q260': 'gender', 'Q272': 'language', 'Q273': 'marital_status',\n",
    "        'Q275R': 'education_level', 'Q287': 'social_class'\n",
    "    }\n",
    "    wvs_df.rename(columns=demographic_mapping, inplace=True)\n",
    "\n",
    "    #print(wvs_df['region'].unique())\n",
    "\n",
    "    not_scale_questions = [\"Q42\", \"Q90\", \"Q149\", \"Q150\", \"Q151\"]\n",
    "    demographic_cols = list(demographic_mapping.values())\n",
    "    selected_questions = [q for q in gemma_df.columns if q.startswith('Q')]\n",
    "\n",
    "    print(\"Converting text answers to numeric codes...\")\n",
    "    for df in [wvs_df, gemma_df]:\n",
    "        for col in selected_questions:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].apply(\n",
    "                    lambda x: flat_answer_mapping.get(str(x).strip(), x) if isinstance(x, str) else x\n",
    "                )\n",
    "\n",
    "    # --- Persona Alignment ---\n",
    "    merge_cols = [col for col in demographic_cols if col in gemma_df.columns and col in wvs_df.columns]\n",
    "    print(f\"Aligning survey and model data on columns: {merge_cols}\")\n",
    "    merged_df = pd.merge(wvs_df, gemma_df, on=merge_cols, how='inner')\n",
    "    print(f\"Found {len(merged_df)} matching personas between the two datasets.\")\n",
    "\n",
    "    if len(merged_df) == 0:\n",
    "        print(\"No matching personas found.\")\n",
    "        return {}\n",
    "\n",
    "    # --- Metric Calculation ---\n",
    "\n",
    "    # NEW: Main conditional block for region-wise vs. complete analysis\n",
    "    if region_wise:\n",
    "        print(\"\\nCalculating metrics region-wise...\")\n",
    "        results_by_region = {}\n",
    "        # Ensure the 'region' column exists before grouping\n",
    "        if 'region' not in merged_df.columns:\n",
    "            raise ValueError(\"Region column not found in merged data. Cannot perform region-wise analysis.\")\n",
    "            \n",
    "        unique_regions = merged_df['region'].unique()\n",
    "        #print(unique_regions)\n",
    "        \n",
    "        for region in unique_regions:\n",
    "            region_df = merged_df[merged_df['region'] == region]\n",
    "            \n",
    "            hard_metric_scores, soft_metric_scores = [], []\n",
    "            for q in selected_questions:\n",
    "                survey_col, gemma_col = f\"{q}_x\", f\"{q}_y\"\n",
    "                if survey_col not in region_df.columns or gemma_col not in region_df.columns:\n",
    "                    continue\n",
    "                \n",
    "                # Perform calculation on the region-specific dataframe\n",
    "                survey_answers = pd.to_numeric(region_df[survey_col], errors='coerce')\n",
    "                model_answers = pd.to_numeric(region_df[gemma_col], errors='coerce')\n",
    "                valid_indices = (survey_answers.notna()) & (model_answers.notna()) & (survey_answers >= 0)\n",
    "                if not valid_indices.any(): continue\n",
    "                \n",
    "                survey_answers = survey_answers[valid_indices]\n",
    "                model_answers = model_answers[valid_indices]\n",
    "\n",
    "                # Metric Logic (same as before)\n",
    "                if metric_type == 'hard':\n",
    "                    scores = (survey_answers == model_answers).astype(int)\n",
    "                    hard_metric_scores.extend(scores)\n",
    "                else:\n",
    "                    if q in not_scale_questions:\n",
    "                        scores = (survey_answers == model_answers).astype(int)\n",
    "                        soft_metric_scores.extend(scores)\n",
    "                    else:\n",
    "                        num_options = num_options_map.get(q)\n",
    "                        if not num_options or num_options <= 1: continue\n",
    "                        error = np.abs(survey_answers - model_answers)\n",
    "                        normalized_error = error / (num_options - 1)\n",
    "                        scores = 1 - normalized_error\n",
    "                        soft_metric_scores.extend(scores)\n",
    "            \n",
    "            # Store results for the current region\n",
    "            region_results = {}\n",
    "            if hard_metric_scores: region_results['hard_metric'] = np.mean(hard_metric_scores)\n",
    "            if soft_metric_scores: region_results['soft_metric_unified'] = np.mean(soft_metric_scores)\n",
    "            results_by_region[region] = region_results\n",
    "            \n",
    "        return results_by_region\n",
    "\n",
    "    else: # MODIFIED: Original logic is now in the else block\n",
    "        print(f\"\\nCalculating metrics for complete dataset with mode: '{metric_type}'...\")\n",
    "        hard_metric_scores, soft_metric_scores = [], []\n",
    "        for q in selected_questions:\n",
    "            # (Calculation logic is the same as the inner loop above, but on merged_df)\n",
    "            survey_col, gemma_col = f\"{q}_x\", f\"{q}_y\"\n",
    "            if survey_col not in merged_df.columns or gemma_col not in merged_df.columns: continue\n",
    "            survey_answers = pd.to_numeric(merged_df[survey_col], errors='coerce')\n",
    "            model_answers = pd.to_numeric(merged_df[gemma_col], errors='coerce')\n",
    "            valid_indices = (survey_answers.notna()) & (model_answers.notna()) & (survey_answers >= 0)\n",
    "            if not valid_indices.any(): continue\n",
    "            survey_answers = survey_answers[valid_indices]\n",
    "            model_answers = model_answers[valid_indices]\n",
    "\n",
    "            if metric_type == 'hard':\n",
    "                scores = (survey_answers == model_answers).astype(int)\n",
    "                hard_metric_scores.extend(scores)\n",
    "            else:\n",
    "                if q in not_scale_questions:\n",
    "                    scores = (survey_answers == model_answers).astype(int)\n",
    "                    soft_metric_scores.extend(scores)\n",
    "                else:\n",
    "                    num_options = num_options_map.get(q)\n",
    "                    if not num_options or num_options <= 1: continue\n",
    "                    error = np.abs(survey_answers - model_answers)\n",
    "                    normalized_error = error / (num_options - 1)\n",
    "                    scores = 1 - normalized_error\n",
    "                    soft_metric_scores.extend(scores)\n",
    "\n",
    "        results = {}\n",
    "        if hard_metric_scores: results['hard_metric'] = np.mean(hard_metric_scores)\n",
    "        if soft_metric_scores: results['soft_metric_unified'] = np.mean(soft_metric_scores)\n",
    "        if not results: print(\"\\nNo scores were calculated.\")\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0dfe2f9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing WVS column names...\n",
      "Converting text answers to numeric codes...\n",
      "Aligning survey and model data on columns: ['region', 'urban_rural', 'age', 'gender', 'language', 'marital_status', 'education_level', 'social_class']\n",
      "Found 74 matching personas between the two datasets.\n",
      "\n",
      "Calculating metrics region-wise...\n",
      "\n",
      "--- FINAL RESULTS (Region-Wise) ---\n",
      "{\n",
      "    \"IN-BR Bihar\": {\n",
      "        \"soft_metric_unified\": 0.49566531456295243\n",
      "    },\n",
      "    \"IN-DL Delhi\": {\n",
      "        \"soft_metric_unified\": 0.5384818691193574\n",
      "    },\n",
      "    \"IN-HR Haryana\": {\n",
      "        \"soft_metric_unified\": 0.5542461653572766\n",
      "    },\n",
      "    \"IN-MH Maharashtra\": {\n",
      "        \"soft_metric_unified\": 0.6021673291690327\n",
      "    },\n",
      "    \"IN-PB Punjab\": {\n",
      "        \"soft_metric_unified\": 0.5697480267152399\n",
      "    },\n",
      "    \"IN-TG Telangana\": {\n",
      "        \"soft_metric_unified\": 0.5008028259473346\n",
      "    },\n",
      "    \"IN-UP Uttar Pradesh\": {\n",
      "        \"soft_metric_unified\": 0.5821424873149011\n",
      "    },\n",
      "    \"IN-WB West Bengal\": {\n",
      "        \"soft_metric_unified\": 0.5792525773195877\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "results_soft = analyze_survey_alignment(region_wise=True)\n",
    "print(\"\\n--- FINAL RESULTS (Region-Wise) ---\")\n",
    "print(json.dumps(results_soft, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ed67820c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardizing WVS column names...\n",
      "Converting text answers to numeric codes...\n",
      "Aligning survey and model data on columns: ['region', 'urban_rural', 'age', 'gender', 'language', 'marital_status', 'education_level', 'social_class']\n",
      "Found 74 matching personas between the two datasets.\n",
      "\n",
      "Calculating metrics region-wise...\n",
      "\n",
      "--- FINAL RESULTS (Region-Wise) ---\n",
      "{\n",
      "    \"IN-BR Bihar\": {\n",
      "        \"hard_metric\": 0.3185397279885469\n",
      "    },\n",
      "    \"IN-DL Delhi\": {\n",
      "        \"hard_metric\": 0.3691722169362512\n",
      "    },\n",
      "    \"IN-HR Haryana\": {\n",
      "        \"hard_metric\": 0.3400673400673401\n",
      "    },\n",
      "    \"IN-MH Maharashtra\": {\n",
      "        \"hard_metric\": 0.3577512776831346\n",
      "    },\n",
      "    \"IN-PB Punjab\": {\n",
      "        \"hard_metric\": 0.34972677595628415\n",
      "    },\n",
      "    \"IN-TG Telangana\": {\n",
      "        \"hard_metric\": 0.3815028901734104\n",
      "    },\n",
      "    \"IN-UP Uttar Pradesh\": {\n",
      "        \"hard_metric\": 0.37698042870456666\n",
      "    },\n",
      "    \"IN-WB West Bengal\": {\n",
      "        \"hard_metric\": 0.34536082474226804\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "results_hard = analyze_survey_alignment(metric_type='hard',  region_wise=True)\n",
    "print(\"\\n--- FINAL RESULTS (Region-Wise) ---\")\n",
    "print(json.dumps(results_hard, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3321b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
